{
    "config": {
        "data": {
            "cat_policy": "ohe",
            "path": "data/credit-g"
        },
        "fit": {
            "early_stopping_rounds": 50,
            "verbose": false
        },
        "model": {
            "alpha": 0,
            "booster": "gbtree",
            "colsample_bylevel": 0.6040514356057036,
            "colsample_bytree": 0.5876097317209871,
            "gamma": 0.0009972538800380253,
            "lambda": 2.886850217417765e-07,
            "learning_rate": 0.163011966646272,
            "max_depth": 5,
            "min_child_weight": 0.01792550419215392,
            "n_estimators": 2000,
            "n_jobs": -1,
            "subsample": 0.8580292141839648,
            "tree_method": "gpu_hist"
        },
        "seed": 8
    },
    "environment": {
        "devices": {
            "CUDA_VISIBLE_DEVICES": null,
            "torch.version.cuda": "10.1",
            "torch.backends.cudnn.version()": 7603,
            "torch.cuda.nccl.version()": 2708,
            "driver": "470.256.02"
        }
    },
    "dataset": "credit-g",
    "algorithm": "xgboost_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9862385321100917,
                "recall": 0.8921161825726142,
                "f1-score": 0.9368191721132899,
                "support": 241
            },
            "1": {
                "precision": 0.9553264604810997,
                "recall": 0.9946332737030411,
                "f1-score": 0.974583698510079,
                "support": 559
            },
            "accuracy": 0.96375,
            "macro avg": {
                "precision": 0.9707824962955958,
                "recall": 0.9433747281378276,
                "f1-score": 0.9557014353116844,
                "support": 800
            },
            "weighted avg": {
                "precision": 0.9646387220593334,
                "recall": 0.96375,
                "f1-score": 0.9632071349330463,
                "support": 800
            },
            "roc_auc": 0.9963108395994626,
            "score": 0.96375
        },
        "val": {
            "0": {
                "precision": 0.9047619047619048,
                "recall": 0.6129032258064516,
                "f1-score": 0.7307692307692307,
                "support": 31
            },
            "1": {
                "precision": 0.8481012658227848,
                "recall": 0.9710144927536232,
                "f1-score": 0.9054054054054054,
                "support": 69
            },
            "accuracy": 0.86,
            "macro avg": {
                "precision": 0.8764315852923448,
                "recall": 0.7919588592800374,
                "f1-score": 0.818087318087318,
                "support": 100
            },
            "weighted avg": {
                "precision": 0.865666063893912,
                "recall": 0.86,
                "f1-score": 0.8512681912681913,
                "support": 100
            },
            "roc_auc": 0.8705002337540907,
            "score": 0.86
        },
        "test": {
            "0": {
                "precision": 0.55,
                "recall": 0.39285714285714285,
                "f1-score": 0.45833333333333337,
                "support": 28
            },
            "1": {
                "precision": 0.7875,
                "recall": 0.875,
                "f1-score": 0.8289473684210527,
                "support": 72
            },
            "accuracy": 0.74,
            "macro avg": {
                "precision": 0.66875,
                "recall": 0.6339285714285714,
                "f1-score": 0.6436403508771931,
                "support": 100
            },
            "weighted avg": {
                "precision": 0.721,
                "recall": 0.74,
                "f1-score": 0.7251754385964913,
                "support": 100
            },
            "roc_auc": 0.746031746031746,
            "score": 0.74
        }
    },
    "time": "0:00:01"
}

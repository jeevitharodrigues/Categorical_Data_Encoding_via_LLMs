{
    "config": {
        "data": {
            "cat_policy": "ohe",
            "path": "data/credit-approval"
        },
        "fit": {
            "early_stopping_rounds": 50,
            "verbose": false
        },
        "model": {
            "alpha": 0,
            "booster": "gbtree",
            "colsample_bylevel": 0.7479875860502782,
            "colsample_bytree": 0.7892656746801335,
            "gamma": 0,
            "lambda": 0,
            "learning_rate": 0.04486879472147982,
            "max_depth": 8,
            "min_child_weight": 2.541074371450198e-08,
            "n_estimators": 2000,
            "n_jobs": -1,
            "subsample": 0.683657763245091,
            "tree_method": "gpu_hist"
        },
        "seed": 3
    },
    "environment": {
        "devices": {
            "CUDA_VISIBLE_DEVICES": null,
            "torch.version.cuda": "10.1",
            "torch.backends.cudnn.version()": 7603,
            "torch.cuda.nccl.version()": 2708,
            "driver": "470.256.02"
        }
    },
    "dataset": "credit-approval",
    "algorithm": "xgboost_",
    "metrics": {
        "train": {
            "0": {
                "precision": 1.0,
                "recall": 1.0,
                "f1-score": 1.0,
                "support": 315
            },
            "1": {
                "precision": 1.0,
                "recall": 1.0,
                "f1-score": 1.0,
                "support": 237
            },
            "accuracy": 1.0,
            "macro avg": {
                "precision": 1.0,
                "recall": 1.0,
                "f1-score": 1.0,
                "support": 552
            },
            "weighted avg": {
                "precision": 1.0,
                "recall": 1.0,
                "f1-score": 1.0,
                "support": 552
            },
            "roc_auc": 1.0,
            "score": 1.0
        },
        "val": {
            "0": {
                "precision": 0.9210526315789473,
                "recall": 0.9210526315789473,
                "f1-score": 0.9210526315789473,
                "support": 38
            },
            "1": {
                "precision": 0.9032258064516129,
                "recall": 0.9032258064516129,
                "f1-score": 0.9032258064516129,
                "support": 31
            },
            "accuracy": 0.9130434782608695,
            "macro avg": {
                "precision": 0.9121392190152802,
                "recall": 0.9121392190152802,
                "f1-score": 0.9121392190152802,
                "support": 69
            },
            "weighted avg": {
                "precision": 0.9130434782608695,
                "recall": 0.9130434782608695,
                "f1-score": 0.9130434782608695,
                "support": 69
            },
            "roc_auc": 0.9185059422750425,
            "score": 0.9130434782608695
        },
        "test": {
            "0": {
                "precision": 0.7297297297297297,
                "recall": 0.9,
                "f1-score": 0.8059701492537312,
                "support": 30
            },
            "1": {
                "precision": 0.90625,
                "recall": 0.7435897435897436,
                "f1-score": 0.8169014084507042,
                "support": 39
            },
            "accuracy": 0.8115942028985508,
            "macro avg": {
                "precision": 0.8179898648648649,
                "recall": 0.8217948717948718,
                "f1-score": 0.8114357788522177,
                "support": 69
            },
            "weighted avg": {
                "precision": 0.8295020564042302,
                "recall": 0.8115942028985508,
                "f1-score": 0.812148687060716,
                "support": 69
            },
            "roc_auc": 0.8713675213675214,
            "score": 0.8115942028985508
        }
    },
    "time": "0:00:01"
}

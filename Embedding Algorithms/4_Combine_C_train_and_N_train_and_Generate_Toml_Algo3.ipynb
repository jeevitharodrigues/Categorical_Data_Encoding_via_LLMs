{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5H_kJbu949H"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "import tqdm\n",
        "import toml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "YpWaiq9p-BMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ip_base_path = \"/content/drive/MyDrive/Colab Notebooks/TempTestFolder/Input Data\"\n",
        "model_op_base_path = \"/content/drive/MyDrive/Colab Notebooks/TempTestFolder/3_Default_LLM_Prompt_for_each_row\"\n",
        "final_op_base_path = \"/content/drive/MyDrive/Colab Notebooks/TempTestFolder/Final Data\""
      ],
      "metadata": {
        "id": "oa67O1hMMWQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the C_train, C_test, C_val generated from 3-Default LLM Prompt for each row with then N_train, N_test, N_val with original data because now everything is numeric\n",
        "# Also Create info.json files\n",
        "# Here basically we are dealing with folders such as adult_algo_3, bank_marketing_algo_3\n",
        "\n",
        "algo_list = [\"3_Embedding_Prompt_for_each_row\"]\n",
        "data_list = [\"adult\", \"analcatdata\", \"bank_marketing\", \"credit-approval\", \"credit-g\", \"cylinder-bands\", \"dresses-sales\", \"eucalyptus\", \"kr-vs-kp\", \"nursery\", \"titanic\", \"sick\"]\n",
        "for algo in algo_list:\n",
        "  for data in tqdm.tqdm(data_list):\n",
        "    new_data_name = f\"{data}_algo_{algo.split('_')[0]}\"\n",
        "    ip_path = f\"{ip_base_path}/{data}\"\n",
        "    model_op_path = f\"{model_op_base_path}/{data}\"\n",
        "    final_op_path = f\"{final_op_base_path}/{new_data_name}\"\n",
        "\n",
        "    os.makedirs(f\"{final_op_path}\", exist_ok=True)\n",
        "\n",
        "    y_train = np.load(f\"{ip_path}/y_train.npy\", allow_pickle=True)\n",
        "    y_train_df = pd.DataFrame(y_train)\n",
        "\n",
        "    y_test = np.load(f\"{ip_path}/y_test.npy\", allow_pickle=True)\n",
        "    y_val = np.load(f\"{ip_path}/y_val.npy\", allow_pickle=True)\n",
        "\n",
        "    if((data != \"analcatdata\") and (data != \"nursery\") and (data != \"kr-vs-kp\")):\n",
        "      default_N_train = np.load(f\"{ip_path}/N_train.npy\", allow_pickle=True)\n",
        "      C_train = np.load(f\"{model_op_path}/C_train.npy\", allow_pickle=True)\n",
        "      final_N_train = np.concatenate((default_N_train, C_train), axis=1)\n",
        "      np.save(f\"{final_op_path}/N_train.npy\", final_N_train.astype(np.float32))\n",
        "\n",
        "      default_N_val = np.load(f\"{ip_path}/N_val.npy\", allow_pickle=True)\n",
        "      C_val =  np.load(f\"{model_op_path}/C_val.npy\", allow_pickle=True)\n",
        "      final_N_val = np.concatenate((default_N_val, C_val), axis=1)\n",
        "      np.save(f\"{final_op_path}/N_val.npy\", final_N_val.astype(np.float32))\n",
        "\n",
        "      default_N_test = np.load(f\"{ip_path}/N_test.npy\", allow_pickle=True)\n",
        "      C_test = np.load(f\"{model_op_path}/C_test.npy\", allow_pickle=True)\n",
        "      final_N_test = np.concatenate((default_N_test, C_test), axis=1)\n",
        "      np.save(f\"{final_op_path}/N_test.npy\", final_N_test.astype(np.float32))\n",
        "\n",
        "      info_dict = {\n",
        "              \"name\": f\"{new_data_name}\",\n",
        "              \"basename\": f\"{new_data_name}\",\n",
        "              \"split\": 0,\n",
        "              \"task_type\": \"binclass\" if y_train_df[0].nunique() == 2 else \"multiclass\",\n",
        "              \"n_classes\": y_train_df[0].nunique(),\n",
        "              \"n_num_features\": final_N_train.shape[1],\n",
        "              \"n_cat_features\": 0,\n",
        "              \"train_size\": final_N_train.shape[0],\n",
        "              \"val_size\": final_N_val.shape[0],\n",
        "              \"test_size\": final_N_test.shape[0]\n",
        "          }\n",
        "\n",
        "    else:\n",
        "      C_train = np.load(f\"{model_op_path}/C_train.npy\", allow_pickle=True)\n",
        "      np.save(f\"{final_op_path}/N_train.npy\", C_train.astype(np.float32))\n",
        "\n",
        "      C_val = np.load(f\"{model_op_path}/C_val.npy\", allow_pickle=True)\n",
        "      np.save(f\"{final_op_path}/N_val.npy\", C_val.astype(np.float32))\n",
        "\n",
        "      C_test = np.load(f\"{model_op_path}/C_test.npy\", allow_pickle=True)\n",
        "      np.save(f\"{final_op_path}/N_test.npy\", C_test.astype(np.float32))\n",
        "\n",
        "      info_dict = {\n",
        "              \"name\": f\"{new_data_name}\",\n",
        "              \"basename\": f\"{new_data_name}\",\n",
        "              \"split\": 0,\n",
        "              \"task_type\": \"binclass\" if y_train_df[0].nunique() == 2 else \"multiclass\",\n",
        "              \"n_classes\": y_train_df[0].nunique(),\n",
        "              \"n_num_features\": C_train.shape[1],\n",
        "              \"n_cat_features\": 0,\n",
        "              \"train_size\": C_train.shape[0],\n",
        "              \"val_size\": C_val.shape[0],\n",
        "              \"test_size\": C_test.shape[0]\n",
        "          }\n",
        "\n",
        "    np.save(f\"{final_op_path}/y_train.npy\", y_train.astype(np.int64))\n",
        "    np.save(f\"{final_op_path}/y_test.npy\", y_test.astype(np.int64))\n",
        "    np.save(f\"{final_op_path}/y_val.npy\", y_val.astype(np.int64))\n",
        "\n",
        "\n",
        "    print(f\"For {new_data_name} =======\")\n",
        "    print(info_dict)\n",
        "    print(f\"shape of y_train = {y_train.shape}, y_val = {y_val.shape}, y_test = {y_test.shape} \")\n",
        "    print()\n",
        "\n",
        "    with open(f\"{final_op_path}/info.json\", 'w') as fp:\n",
        "      json.dump(info_dict, fp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VB4dohEpMjU2",
        "outputId": "b917fb73-f2a5-47b2-b453-733896f71c4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:03<00:00,  3.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For adult_algo_3 =======\n",
            "{'name': 'adult_algo_3', 'basename': 'adult_algo_3', 'split': 0, 'task_type': 'binclass', 'n_classes': 2, 'n_num_features': 774, 'n_cat_features': 0, 'train_size': 39074, 'val_size': 4884, 'test_size': 4884}\n",
            "shape of y_train = (39074,), y_val = (4884,), y_test = (4884,) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now copy default datasets intp Final Data Folder\n",
        "for data in tqdm.tqdm(data_list):\n",
        "    !cp -r '{ip_base_path}/{data}' '{final_op_base_path}/'"
      ],
      "metadata": {
        "id": "iozRu9Mw-oLD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01438816-604d-44ca-f3a2-658deb104612"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now create info.json files for default datasets and keep it in Benchmark Data folder\n",
        "\n",
        "for data in tqdm.tqdm(data_list):\n",
        "\n",
        "  y_train = np.load(f\"{final_op_base_path}/{data}/y_train.npy\", allow_pickle=True)\n",
        "  y_train_df = pd.DataFrame(y_train)\n",
        "\n",
        "  y_test = np.load(f\"{final_op_base_path}/{data}/y_test.npy\", allow_pickle=True)\n",
        "  y_val = np.load(f\"{final_op_base_path}/{data}/y_val.npy\", allow_pickle=True)\n",
        "\n",
        "  if((data != \"analcatdata\") and (data != \"nursery\") and (data != \"kr-vs-kp\")):\n",
        "    default_N_train = np.load(f\"{final_op_base_path}/{data}/N_train.npy\", allow_pickle=True)\n",
        "\n",
        "    default_N_test = np.load(f\"{final_op_base_path}/{data}/N_test.npy\", allow_pickle=True)\n",
        "\n",
        "    default_N_val = np.load(f\"{final_op_base_path}/{data}/N_val.npy\", allow_pickle=True)\n",
        "\n",
        "    default_C_train = np.load(f\"{final_op_base_path}/{data}/C_train.npy\", allow_pickle=True)\n",
        "\n",
        "    info_dict = {\n",
        "                  \"name\": data,\n",
        "                  \"basename\": data,\n",
        "                  \"split\": 0,\n",
        "                  \"task_type\": \"binclass\" if y_train_df[0].nunique() == 2 else \"multiclass\",\n",
        "                  \"n_classes\": y_train_df[0].nunique(),\n",
        "                  \"n_num_features\": default_N_train.shape[1],\n",
        "                  \"n_cat_features\": default_C_train.shape[1],\n",
        "                  \"train_size\": default_N_train.shape[0],\n",
        "                  \"val_size\": default_N_val.shape[0],\n",
        "                  \"test_size\": default_N_test.shape[0]\n",
        "              }\n",
        "\n",
        "  else:\n",
        "    default_C_train = np.load(f\"{final_op_base_path}/{data}/C_train.npy\", allow_pickle=True)\n",
        "    default_C_val = np.load(f\"{final_op_base_path}/{data}/C_val.npy\", allow_pickle=True)\n",
        "    default_C_test = np.load(f\"{final_op_base_path}/{data}/C_test.npy\", allow_pickle=True)\n",
        "\n",
        "    info_dict = {\n",
        "                  \"name\": data,\n",
        "                  \"basename\": data,\n",
        "                  \"split\": 0,\n",
        "                  \"task_type\": \"binclass\" if y_train_df[0].nunique() == 2 else \"multiclass\",\n",
        "                  \"n_classes\": y_train_df[0].nunique(),\n",
        "                  \"n_num_features\": 0,\n",
        "                  \"n_cat_features\": default_C_train.shape[1],\n",
        "                  \"train_size\": default_C_train.shape[0],\n",
        "                  \"val_size\": default_C_val.shape[0],\n",
        "                  \"test_size\": default_C_test.shape[0]\n",
        "              }\n",
        "\n",
        "  np.save(f\"{final_op_base_path}/{data}/y_train.npy\", y_train.astype(np.int64))\n",
        "  np.save(f\"{final_op_base_path}/{data}/y_test.npy\", y_test.astype(np.int64))\n",
        "  np.save(f\"{final_op_base_path}/{data}/y_val.npy\", y_val.astype(np.int64))\n",
        "\n",
        "\n",
        "  print(f\"For {data} =======\")\n",
        "  print(info_dict)\n",
        "  print(f\"shape of y_train = {y_train.shape}, y_val = {y_val.shape}, y_test = {y_test.shape} \")\n",
        "  print()\n",
        "\n",
        "  with open(f\"{final_op_base_path}/{data}/info.json\", 'w') as fp:\n",
        "    json.dump(info_dict, fp)"
      ],
      "metadata": {
        "id": "yX6hJaVa-fVI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b447de48-c9a9-4ff6-ca0d-90bd6f663cd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  6.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For adult =======\n",
            "{'name': 'adult', 'basename': 'adult', 'split': 0, 'task_type': 'binclass', 'n_classes': 2, 'n_num_features': 6, 'n_cat_features': 8, 'train_size': 39074, 'val_size': 4884, 'test_size': 4884}\n",
            "shape of y_train = (39074,), y_val = (4884,), y_test = (4884,) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Type cast all categorical data to '<U26'\n",
        "\n",
        "for data in tqdm.tqdm(data_list):\n",
        "  default_C_train = np.load(f\"{final_op_base_path}/{data}/C_train.npy\", allow_pickle=True)\n",
        "  default_C_train = np.where(default_C_train == 'None', 'nan', default_C_train)\n",
        "\n",
        "  default_C_test = np.load(f\"{final_op_base_path}/{data}/C_test.npy\", allow_pickle=True)\n",
        "  default_C_test = np.where(default_C_test == 'None', 'nan', default_C_test)\n",
        "\n",
        "  default_C_val = np.load(f\"{final_op_base_path}/{data}/C_val.npy\", allow_pickle=True)\n",
        "  default_C_val = np.where(default_C_val == 'None', 'nan', default_C_val)\n",
        "\n",
        "  np.save(f\"{final_op_base_path}/{data}/C_train.npy\", default_C_train.astype('<U26'))\n",
        "  np.save(f\"{final_op_base_path}/{data}/C_test.npy\", default_C_test.astype('<U26'))\n",
        "  np.save(f\"{final_op_base_path}/{data}/C_val.npy\", default_C_val.astype('<U26'))\n"
      ],
      "metadata": {
        "id": "1HP2t9qn-pk1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c359fd1f-4e14-4de1-cc73-3f595e6e2367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.62it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for data in tqdm.tqdm(data_list):\n",
        "  if((data != \"analcatdata\") and (data != \"nursery\") and (data != \"kr-vs-kp\")):\n",
        "    default_N_train = np.load(f\"{final_op_base_path}/{data}/N_train.npy\", allow_pickle=True)\n",
        "\n",
        "    default_N_test = np.load(f\"{final_op_base_path}/{data}/N_test.npy\", allow_pickle=True)\n",
        "\n",
        "    default_N_val = np.load(f\"{final_op_base_path}/{data}/N_val.npy\", allow_pickle=True)\n",
        "\n",
        "    np.save(f\"{final_op_base_path}/{data}/N_train.npy\", default_N_train.astype(np.float32))\n",
        "    np.save(f\"{final_op_base_path}/{data}/N_test.npy\", default_N_test.astype(np.float32))\n",
        "    np.save(f\"{final_op_base_path}/{data}/N_val.npy\", default_N_val.astype(np.float32))"
      ],
      "metadata": {
        "id": "vdcAtQgr-rEp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b1a93e5-c5fa-4910-ede6-1a94e61b0cb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 15.90it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !zip -r  \"{final_op_base_path}/data.zip\" \"{final_op_base_path}\""
      ],
      "metadata": {
        "id": "rLjx3nxl-sVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp -r \"/content/drive/MyDrive/Colab Notebooks/19-21 Oct 2024-Final for publishing/data\" \"/content/drive/MyDrive/Colab Notebooks/TempTestFolder\""
      ],
      "metadata": {
        "id": "nB8umeGuQKcU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
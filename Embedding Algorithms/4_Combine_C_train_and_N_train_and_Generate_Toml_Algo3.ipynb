{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5H_kJbu949H"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "import tqdm\n",
        "import toml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "YpWaiq9p-BMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = \"/content/drive/MyDrive/Colab Notebooks/20-30 Oct 2024- Test Data Algo1-2-3_mlp\""
      ],
      "metadata": {
        "id": "WzOR-iwr-CZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the C_train, C_test, C_val generated from 3-Default LLM Prompt for each row with then N_train, N_test, N_val with original data because now everything is numeric\n",
        "# Also Create info.json files\n",
        "# Here basically we are dealing with folders such as adult_algo_3, bank_marketing_algo_3\n",
        "\n",
        "algo_list = [\"3_Embedding_Prompt_for_each_row\"]\n",
        "data_list = [\"adult\", \"analcatdata\", \"bank_marketing\", \"credit-approval\", \"credit-g\", \"cylinder-bands\", \"dresses-sales\", \"eucalyptus\", \"kr-vs-kp\", \"nursery\", \"titanic\", \"sick\"]\n",
        "for algo in algo_list:\n",
        "  for data in tqdm.tqdm(data_list):\n",
        "    dir_name = f\"{data}_algo_{algo.split('_')[0]}\"\n",
        "    path = f\"{base_path}/Final Data/{dir_name}\"\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "    y_train = np.load(f\"{base_path}/Benchmark Data/{data}/y_train.npy\", allow_pickle=True)\n",
        "    y_train_df = pd.DataFrame(y_train)\n",
        "\n",
        "    y_test = np.load(f\"{base_path}/Benchmark Data/{data}/y_test.npy\", allow_pickle=True)\n",
        "    y_val = np.load(f\"{base_path}/Benchmark Data/{data}/y_val.npy\", allow_pickle=True)\n",
        "\n",
        "    if((data != \"analcatdata\") and (data != \"nursery\")):\n",
        "      default_N_train = np.load(f\"{base_path}/Benchmark Data/{data}/N_train.npy\", allow_pickle=True)\n",
        "      C_train = np.load(f\"{base_path}/{algo}/{data}/C_train.npy\", allow_pickle=True)\n",
        "      final_N_train = np.concatenate((default_N_train, C_train), axis=1)\n",
        "      np.save(f\"{path}/N_train.npy\", final_N_train.astype(np.float32))\n",
        "\n",
        "      default_N_val = np.load(f\"{base_path}/Benchmark Data/{data}/N_val.npy\", allow_pickle=True)\n",
        "      C_val = np.load(f\"{base_path}/{algo}/{data}/C_val.npy\", allow_pickle=True)\n",
        "      final_N_val = np.concatenate((default_N_val, C_val), axis=1)\n",
        "      np.save(f\"{path}/N_val.npy\", final_N_val.astype(np.float32))\n",
        "\n",
        "      default_N_test = np.load(f\"{base_path}/Benchmark Data/{data}/N_test.npy\", allow_pickle=True)\n",
        "      C_test = np.load(f\"{base_path}/{algo}/{data}/C_test.npy\", allow_pickle=True)\n",
        "      final_N_test = np.concatenate((default_N_test, C_test), axis=1)\n",
        "      np.save(f\"{path}/N_test.npy\", final_N_test.astype(np.float32))\n",
        "\n",
        "      info_dict = {\n",
        "              \"name\": dir_name,\n",
        "              \"basename\": dir_name,\n",
        "              \"split\": 0,\n",
        "              \"task_type\": \"binclass\" if y_train_df[0].nunique() == 2 else \"multiclass\",\n",
        "              \"n_classes\": y_train_df[0].nunique(),\n",
        "              \"n_num_features\": final_N_train.shape[1],\n",
        "              \"n_cat_features\": 0,\n",
        "              \"train_size\": final_N_train.shape[0],\n",
        "              \"val_size\": final_N_val.shape[0],\n",
        "              \"test_size\": final_N_test.shape[0]\n",
        "          }\n",
        "\n",
        "    else:\n",
        "      C_train = np.load(f\"{base_path}/{algo}/{data}/C_train.npy\", allow_pickle=True)\n",
        "      np.save(f\"{path}/N_train.npy\", C_train.astype(np.float32))\n",
        "\n",
        "      C_val = np.load(f\"{base_path}/{algo}/{data}/C_val.npy\", allow_pickle=True)\n",
        "      np.save(f\"{path}/N_val.npy\", C_val.astype(np.float32))\n",
        "\n",
        "      C_test = np.load(f\"{base_path}/{algo}/{data}/C_test.npy\", allow_pickle=True)\n",
        "      np.save(f\"{path}/N_test.npy\", C_test.astype(np.float32))\n",
        "\n",
        "      info_dict = {\n",
        "              \"name\": dir_name,\n",
        "              \"basename\": dir_name,\n",
        "              \"split\": 0,\n",
        "              \"task_type\": \"binclass\" if y_train_df[0].nunique() == 2 else \"multiclass\",\n",
        "              \"n_classes\": y_train_df[0].nunique(),\n",
        "              \"n_num_features\": C_train.shape[1],\n",
        "              \"n_cat_features\": 0,\n",
        "              \"train_size\": C_train.shape[0],\n",
        "              \"val_size\": C_val.shape[0],\n",
        "              \"test_size\": C_test.shape[0]\n",
        "          }\n",
        "\n",
        "    np.save(f\"{path}/y_train.npy\", y_train.astype(np.int64))\n",
        "    np.save(f\"{path}/y_test.npy\", y_test.astype(np.int64))\n",
        "    np.save(f\"{path}/y_val.npy\", y_val.astype(np.int64))\n",
        "\n",
        "\n",
        "    print(f\"For {dir_name} =======\")\n",
        "    print(info_dict)\n",
        "    print(f\"shape of y_train = {y_train.shape}, y_val = {y_val.shape}, y_test = {y_test.shape} \")\n",
        "    print()\n",
        "\n",
        "    with open(f\"{path}/info.json\", 'w') as fp:\n",
        "      json.dump(info_dict, fp)"
      ],
      "metadata": {
        "id": "3VjFZLsE-D1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now create info.json files for default datasets and keep it in Benchmark Data folder\n",
        "\n",
        "for data in tqdm.tqdm(data_list):\n",
        "\n",
        "  y_train = np.load(f\"{base_path}/Benchmark Data/{data}/y_train.npy\", allow_pickle=True)\n",
        "  y_train_df = pd.DataFrame(y_train)\n",
        "\n",
        "  y_test = np.load(f\"{base_path}/Benchmark Data/{data}/y_test.npy\", allow_pickle=True)\n",
        "  y_val = np.load(f\"{base_path}/Benchmark Data/{data}/y_val.npy\", allow_pickle=True)\n",
        "\n",
        "  if((data != \"analcatdata\") and (data != \"kr-vs-kp\")):\n",
        "    default_N_train = np.load(f\"{base_path}/Benchmark Data/{data}/N_train.npy\", allow_pickle=True)\n",
        "\n",
        "    default_N_test = np.load(f\"{base_path}/Benchmark Data/{data}/N_test.npy\", allow_pickle=True)\n",
        "\n",
        "    default_N_val = np.load(f\"{base_path}/Benchmark Data/{data}/N_val.npy\", allow_pickle=True)\n",
        "\n",
        "    default_C_train = np.load(f\"{base_path}/Benchmark Data/{data}/C_train.npy\", allow_pickle=True)\n",
        "\n",
        "    info_dict = {\n",
        "                  \"name\": data,\n",
        "                  \"basename\": data,\n",
        "                  \"split\": 0,\n",
        "                  \"task_type\": \"binclass\" if y_train_df[0].nunique() == 2 else \"multiclass\",\n",
        "                  \"n_classes\": y_train_df[0].nunique(),\n",
        "                  \"n_num_features\": default_N_train.shape[1],\n",
        "                  \"n_cat_features\": default_C_train.shape[1],\n",
        "                  \"train_size\": default_N_train.shape[0],\n",
        "                  \"val_size\": default_N_val.shape[0],\n",
        "                  \"test_size\": default_N_test.shape[0]\n",
        "              }\n",
        "\n",
        "  else:\n",
        "    default_C_train = np.load(f\"{base_path}/Benchmark Data/{data}/C_train.npy\", allow_pickle=True)\n",
        "    default_C_val = np.load(f\"{base_path}/Benchmark Data/{data}/C_val.npy\", allow_pickle=True)\n",
        "    default_C_test = np.load(f\"{base_path}/Benchmark Data/{data}/C_test.npy\", allow_pickle=True)\n",
        "\n",
        "    info_dict = {\n",
        "                  \"name\": data,\n",
        "                  \"basename\": data,\n",
        "                  \"split\": 0,\n",
        "                  \"task_type\": \"binclass\" if y_train_df[0].nunique() == 2 else \"multiclass\",\n",
        "                  \"n_classes\": y_train_df[0].nunique(),\n",
        "                  \"n_num_features\": 0,\n",
        "                  \"n_cat_features\": default_C_train.shape[1],\n",
        "                  \"train_size\": default_C_train.shape[0],\n",
        "                  \"val_size\": default_C_val.shape[0],\n",
        "                  \"test_size\": default_C_test.shape[0]\n",
        "              }\n",
        "\n",
        "  np.save(f\"{path}/y_train.npy\", y_train.astype(np.int64))\n",
        "  np.save(f\"{path}/y_test.npy\", y_test.astype(np.int64))\n",
        "  np.save(f\"{path}/y_val.npy\", y_val.astype(np.int64))\n",
        "\n",
        "\n",
        "  print(f\"For {data} =======\")\n",
        "  print(info_dict)\n",
        "  print(f\"shape of y_train = {y_train.shape}, y_val = {y_val.shape}, y_test = {y_test.shape} \")\n",
        "  print()\n",
        "\n",
        "  with open(f\"{base_path}/Benchmark Data/{data}/info.json\", 'w') as fp:\n",
        "    json.dump(info_dict, fp)"
      ],
      "metadata": {
        "id": "yX6hJaVa-fVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now copy default datasets intp Final Data Folder\n",
        "for data in tqdm.tqdm(data_list):\n",
        "    path = f\"{base_path}/Final Data\"\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "    !cp -r '{base_path}/Benchmark Data/{data}' '{path}'"
      ],
      "metadata": {
        "id": "iozRu9Mw-oLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Type cast all categorical data to '<U26'\n",
        "\n",
        "for data in tqdm.tqdm(data_list):\n",
        "  default_C_train = np.load(f\"{base_path}/Final Data/{data}/C_train.npy\", allow_pickle=True)\n",
        "  default_C_train = np.where(default_C_train == 'None', 'nan', default_C_train)\n",
        "\n",
        "  default_C_test = np.load(f\"{base_path}/Final Data/{data}/C_test.npy\", allow_pickle=True)\n",
        "  default_C_test = np.where(default_C_test == 'None', 'nan', default_C_test)\n",
        "\n",
        "  default_C_val = np.load(f\"{base_path}/Final Data/{data}/C_val.npy\", allow_pickle=True)\n",
        "  default_C_val = np.where(default_C_val == 'None', 'nan', default_C_val)\n",
        "\n",
        "  np.save(f\"{base_path}/Final Data/{data}/C_train.npy\", default_C_train.astype('<U26'))\n",
        "  np.save(f\"{base_path}/Final Data/{data}/C_test.npy\", default_C_test.astype('<U26'))\n",
        "  np.save(f\"{base_path}/Final Data/{data}/C_val.npy\", default_C_val.astype('<U26'))\n"
      ],
      "metadata": {
        "id": "1HP2t9qn-pk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for data in tqdm.tqdm(data_list):\n",
        "  if((data != \"analcatdata\") and (data != \"kr-vs-kp\")):\n",
        "    default_N_train = np.load(f\"{base_path}/Final Data/{data}/N_train.npy\", allow_pickle=True)\n",
        "\n",
        "    default_N_test = np.load(f\"{base_path}/Final Data/{data}/N_test.npy\", allow_pickle=True)\n",
        "\n",
        "    default_N_val = np.load(f\"{base_path}/Final Data/{data}/N_val.npy\", allow_pickle=True)\n",
        "\n",
        "    np.save(f\"{base_path}/Final Data/{data}/N_train.npy\", default_N_train.astype(np.float32))\n",
        "    np.save(f\"{base_path}/Final Data/{data}/N_test.npy\", default_N_test.astype(np.float32))\n",
        "    np.save(f\"{base_path}/Final Data/{data}/N_val.npy\", default_N_val.astype(np.float32))"
      ],
      "metadata": {
        "id": "vdcAtQgr-rEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r  \"{base_path}/data.zip\" \"{base_path}/Final Data\""
      ],
      "metadata": {
        "id": "rLjx3nxl-sVz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}